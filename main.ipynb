{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 1800 total files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "labels = ['Bearing', 'Flywheel', 'Healthy', 'LIV', 'LOV', 'NRV', 'Piston', 'Riderbelt']\n",
    "Faults = {label: idx for idx, label in enumerate(labels)}\n",
    "MaxExpNo = 225\n",
    "\n",
    "# Base path to dataset\n",
    "base_path = os.path.expanduser('~/Downloads/AirCompressor_Data')\n",
    "\n",
    "# Raw data store\n",
    "raw_data = []  # list of dicts: [{'signal': ndarray, 'label': str, 'fault': int}, ...]\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(base_path, label, 'preprocess_Reading*.dat')\n",
    "    files = sorted(glob.glob(path))\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"⚠️ No files found for label: {label}\")\n",
    "        continue\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            signal = np.loadtxt(file, delimiter=',')\n",
    "            raw_data.append({\n",
    "                'signal': signal,\n",
    "                'label': label,\n",
    "                'fault': Faults[label]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading {file}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(raw_data)} total files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 0/1800 entries\n",
      "✅ Processed 10/1800 entries\n",
      "✅ Processed 20/1800 entries\n",
      "✅ Processed 30/1800 entries\n",
      "✅ Processed 40/1800 entries\n",
      "✅ Processed 50/1800 entries\n",
      "✅ Processed 60/1800 entries\n",
      "✅ Processed 70/1800 entries\n",
      "✅ Processed 80/1800 entries\n",
      "✅ Processed 90/1800 entries\n",
      "✅ Processed 100/1800 entries\n",
      "✅ Processed 110/1800 entries\n",
      "✅ Processed 120/1800 entries\n",
      "✅ Processed 130/1800 entries\n",
      "✅ Processed 140/1800 entries\n",
      "✅ Processed 150/1800 entries\n",
      "✅ Processed 160/1800 entries\n",
      "✅ Processed 170/1800 entries\n",
      "✅ Processed 180/1800 entries\n",
      "✅ Processed 190/1800 entries\n",
      "✅ Processed 200/1800 entries\n",
      "✅ Processed 210/1800 entries\n",
      "✅ Processed 220/1800 entries\n",
      "✅ Processed 230/1800 entries\n",
      "✅ Processed 240/1800 entries\n",
      "✅ Processed 250/1800 entries\n",
      "✅ Processed 260/1800 entries\n",
      "✅ Processed 270/1800 entries\n",
      "✅ Processed 280/1800 entries\n",
      "✅ Processed 290/1800 entries\n",
      "✅ Processed 300/1800 entries\n",
      "✅ Processed 310/1800 entries\n",
      "✅ Processed 320/1800 entries\n",
      "✅ Processed 330/1800 entries\n",
      "✅ Processed 340/1800 entries\n",
      "✅ Processed 350/1800 entries\n",
      "✅ Processed 360/1800 entries\n",
      "✅ Processed 370/1800 entries\n",
      "✅ Processed 380/1800 entries\n",
      "✅ Processed 390/1800 entries\n",
      "✅ Processed 400/1800 entries\n",
      "✅ Processed 410/1800 entries\n",
      "✅ Processed 420/1800 entries\n",
      "✅ Processed 430/1800 entries\n",
      "✅ Processed 440/1800 entries\n",
      "✅ Processed 450/1800 entries\n",
      "✅ Processed 460/1800 entries\n",
      "✅ Processed 470/1800 entries\n",
      "✅ Processed 480/1800 entries\n",
      "✅ Processed 490/1800 entries\n",
      "✅ Processed 500/1800 entries\n",
      "✅ Processed 510/1800 entries\n",
      "✅ Processed 520/1800 entries\n",
      "✅ Processed 530/1800 entries\n",
      "✅ Processed 540/1800 entries\n",
      "✅ Processed 550/1800 entries\n",
      "✅ Processed 560/1800 entries\n",
      "✅ Processed 570/1800 entries\n",
      "✅ Processed 580/1800 entries\n",
      "✅ Processed 590/1800 entries\n",
      "✅ Processed 600/1800 entries\n",
      "✅ Processed 610/1800 entries\n",
      "✅ Processed 620/1800 entries\n",
      "✅ Processed 630/1800 entries\n",
      "✅ Processed 640/1800 entries\n",
      "✅ Processed 650/1800 entries\n",
      "✅ Processed 660/1800 entries\n",
      "✅ Processed 670/1800 entries\n",
      "✅ Processed 680/1800 entries\n",
      "✅ Processed 690/1800 entries\n",
      "✅ Processed 700/1800 entries\n",
      "✅ Processed 710/1800 entries\n",
      "✅ Processed 720/1800 entries\n",
      "✅ Processed 730/1800 entries\n",
      "✅ Processed 740/1800 entries\n",
      "✅ Processed 750/1800 entries\n",
      "✅ Processed 760/1800 entries\n",
      "✅ Processed 770/1800 entries\n",
      "✅ Processed 780/1800 entries\n",
      "✅ Processed 790/1800 entries\n",
      "✅ Processed 800/1800 entries\n",
      "✅ Processed 810/1800 entries\n",
      "✅ Processed 820/1800 entries\n",
      "✅ Processed 830/1800 entries\n",
      "✅ Processed 840/1800 entries\n",
      "✅ Processed 850/1800 entries\n",
      "✅ Processed 860/1800 entries\n",
      "✅ Processed 870/1800 entries\n",
      "✅ Processed 880/1800 entries\n",
      "✅ Processed 890/1800 entries\n",
      "✅ Processed 900/1800 entries\n",
      "✅ Processed 910/1800 entries\n",
      "✅ Processed 920/1800 entries\n",
      "✅ Processed 930/1800 entries\n",
      "✅ Processed 940/1800 entries\n",
      "✅ Processed 950/1800 entries\n",
      "✅ Processed 960/1800 entries\n",
      "✅ Processed 970/1800 entries\n",
      "✅ Processed 980/1800 entries\n",
      "✅ Processed 990/1800 entries\n",
      "✅ Processed 1000/1800 entries\n",
      "✅ Processed 1010/1800 entries\n",
      "✅ Processed 1020/1800 entries\n",
      "✅ Processed 1030/1800 entries\n",
      "✅ Processed 1040/1800 entries\n",
      "✅ Processed 1050/1800 entries\n",
      "✅ Processed 1060/1800 entries\n",
      "✅ Processed 1070/1800 entries\n",
      "✅ Processed 1080/1800 entries\n",
      "✅ Processed 1090/1800 entries\n",
      "✅ Processed 1100/1800 entries\n",
      "✅ Processed 1110/1800 entries\n",
      "✅ Processed 1120/1800 entries\n",
      "✅ Processed 1130/1800 entries\n",
      "✅ Processed 1140/1800 entries\n",
      "✅ Processed 1150/1800 entries\n",
      "✅ Processed 1160/1800 entries\n",
      "✅ Processed 1170/1800 entries\n",
      "✅ Processed 1180/1800 entries\n",
      "✅ Processed 1190/1800 entries\n",
      "✅ Processed 1200/1800 entries\n",
      "✅ Processed 1210/1800 entries\n",
      "✅ Processed 1220/1800 entries\n",
      "✅ Processed 1230/1800 entries\n",
      "✅ Processed 1240/1800 entries\n",
      "✅ Processed 1250/1800 entries\n",
      "✅ Processed 1260/1800 entries\n",
      "✅ Processed 1270/1800 entries\n",
      "✅ Processed 1280/1800 entries\n",
      "✅ Processed 1290/1800 entries\n",
      "✅ Processed 1300/1800 entries\n",
      "✅ Processed 1310/1800 entries\n",
      "✅ Processed 1320/1800 entries\n",
      "✅ Processed 1330/1800 entries\n",
      "✅ Processed 1340/1800 entries\n",
      "✅ Processed 1350/1800 entries\n",
      "✅ Processed 1360/1800 entries\n",
      "✅ Processed 1370/1800 entries\n",
      "✅ Processed 1380/1800 entries\n",
      "✅ Processed 1390/1800 entries\n",
      "✅ Processed 1400/1800 entries\n",
      "✅ Processed 1410/1800 entries\n",
      "✅ Processed 1420/1800 entries\n",
      "✅ Processed 1430/1800 entries\n",
      "✅ Processed 1440/1800 entries\n",
      "✅ Processed 1450/1800 entries\n",
      "✅ Processed 1460/1800 entries\n",
      "✅ Processed 1470/1800 entries\n",
      "✅ Processed 1480/1800 entries\n",
      "✅ Processed 1490/1800 entries\n",
      "✅ Processed 1500/1800 entries\n",
      "✅ Processed 1510/1800 entries\n",
      "✅ Processed 1520/1800 entries\n",
      "✅ Processed 1530/1800 entries\n",
      "✅ Processed 1540/1800 entries\n",
      "✅ Processed 1550/1800 entries\n",
      "✅ Processed 1560/1800 entries\n",
      "✅ Processed 1570/1800 entries\n",
      "✅ Processed 1580/1800 entries\n",
      "✅ Processed 1590/1800 entries\n",
      "✅ Processed 1600/1800 entries\n",
      "✅ Processed 1610/1800 entries\n",
      "✅ Processed 1620/1800 entries\n",
      "✅ Processed 1630/1800 entries\n",
      "✅ Processed 1640/1800 entries\n",
      "✅ Processed 1650/1800 entries\n",
      "✅ Processed 1660/1800 entries\n",
      "✅ Processed 1670/1800 entries\n",
      "✅ Processed 1680/1800 entries\n",
      "✅ Processed 1690/1800 entries\n",
      "✅ Processed 1700/1800 entries\n",
      "✅ Processed 1710/1800 entries\n",
      "✅ Processed 1720/1800 entries\n",
      "✅ Processed 1730/1800 entries\n",
      "✅ Processed 1740/1800 entries\n",
      "✅ Processed 1750/1800 entries\n",
      "✅ Processed 1760/1800 entries\n",
      "✅ Processed 1770/1800 entries\n",
      "✅ Processed 1780/1800 entries\n",
      "✅ Processed 1790/1800 entries\n",
      "\n",
      "✅ Feature extraction and DataFrame construction complete.\n",
      "📊 input_data shape: (1800, 109)\n",
      "🎯 target_data shape: (1800, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "# --- Feature Extraction Functions ---\n",
    "\n",
    "def PrimaryFeatureExtractor(X):\n",
    "    rms = np.sqrt(np.mean(np.square(X)))\n",
    "    CrestFactor = np.abs(X).max() / rms\n",
    "    ShapeFactor = rms / np.mean(np.abs(X))\n",
    "    return [[\n",
    "        np.mean(np.abs(X)),\n",
    "        np.min(X),\n",
    "        np.max(X),\n",
    "        np.std(X),\n",
    "        rms,\n",
    "        skew(X),\n",
    "        kurtosis(X),\n",
    "        CrestFactor,\n",
    "        ShapeFactor\n",
    "    ]]\n",
    "\n",
    "def FFT_BasedFeatures(X, NBins=100):\n",
    "    N = len(X)\n",
    "    T = 1.0 / N\n",
    "    FreqList = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n",
    "    X_fft = fft(X)\n",
    "    X_fft[0] = 0\n",
    "    X_fft_magnitude = 2.0 / N * np.abs(X_fft[0:N // 2])\n",
    "\n",
    "    BinCounts = (N // 2) // NBins\n",
    "    SpecEnergy = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(NBins):\n",
    "        SpecEnergy.append(X_fft_magnitude[i * BinCounts:(i + 1) * BinCounts].sum())\n",
    "        labels.append(f'FFT{i + 1}')\n",
    "\n",
    "    return SpecEnergy, labels\n",
    "\n",
    "# --- Data Processing ---\n",
    "\n",
    "feature_rows = []\n",
    "data_columns_FFT_Features = None  # to be initialized during first FFT extraction\n",
    "\n",
    "for idx, entry in enumerate(raw_data):\n",
    "    try:\n",
    "        X = entry['signal']\n",
    "        \n",
    "        # Extract statistical and FFT features\n",
    "        StatFeatures = PrimaryFeatureExtractor(X)[0]\n",
    "        FFT_Features, data_columns_FFT_Features = FFT_BasedFeatures(X)\n",
    "\n",
    "        # Merge all features + fault label\n",
    "        row = StatFeatures + FFT_Features + [entry['fault']]\n",
    "        feature_rows.append(row)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"✅ Processed {idx}/{len(raw_data)} entries\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error extracting features for index {idx}: {e}\")\n",
    "\n",
    "# --- Build DataFrame using original names ---\n",
    "\n",
    "data_columns_PrimaryStatFeatures = [\n",
    "    'Mean', 'Min', 'Max', 'StdDv', 'RMS', 'Skewness',\n",
    "    'Kurtosis', 'CrestFactor', 'ShapeFactor'\n",
    "]\n",
    "data_columns_Target = ['Fault']\n",
    "data_columns = data_columns_PrimaryStatFeatures + data_columns_FFT_Features + data_columns_Target\n",
    "\n",
    "# Create final DataFrame\n",
    "data = pd.DataFrame(feature_rows, columns=data_columns)\n",
    "\n",
    "# Split into inputs and labels\n",
    "input_data = data.drop(columns=['Fault'])\n",
    "target_data = pd.DataFrame(data['Fault'], columns=['Fault'], dtype=int)\n",
    "\n",
    "print(\"\\n✅ Feature extraction and DataFrame construction complete.\")\n",
    "print(f\"📊 input_data shape: {input_data.shape}\")\n",
    "print(f\"🎯 target_data shape: {target_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>StdDv</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>CrestFactor</th>\n",
       "      <th>ShapeFactor</th>\n",
       "      <th>FFT1</th>\n",
       "      <th>...</th>\n",
       "      <th>FFT91</th>\n",
       "      <th>FFT92</th>\n",
       "      <th>FFT93</th>\n",
       "      <th>FFT94</th>\n",
       "      <th>FFT95</th>\n",
       "      <th>FFT96</th>\n",
       "      <th>FFT97</th>\n",
       "      <th>FFT98</th>\n",
       "      <th>FFT99</th>\n",
       "      <th>FFT100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.140067</td>\n",
       "      <td>-1.5920</td>\n",
       "      <td>1.3448</td>\n",
       "      <td>0.186773</td>\n",
       "      <td>0.192985</td>\n",
       "      <td>-0.186858</td>\n",
       "      <td>4.518489</td>\n",
       "      <td>8.249357</td>\n",
       "      <td>1.377799</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187374</td>\n",
       "      <td>-1.4158</td>\n",
       "      <td>1.3472</td>\n",
       "      <td>0.202243</td>\n",
       "      <td>0.239738</td>\n",
       "      <td>-0.297777</td>\n",
       "      <td>3.182940</td>\n",
       "      <td>5.905620</td>\n",
       "      <td>1.279463</td>\n",
       "      <td>0.035926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.201925</td>\n",
       "      <td>-1.3502</td>\n",
       "      <td>1.1123</td>\n",
       "      <td>0.230012</td>\n",
       "      <td>0.259409</td>\n",
       "      <td>-0.205917</td>\n",
       "      <td>1.754806</td>\n",
       "      <td>5.204907</td>\n",
       "      <td>1.284679</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.177199</td>\n",
       "      <td>-1.3254</td>\n",
       "      <td>1.1532</td>\n",
       "      <td>0.223281</td>\n",
       "      <td>0.235517</td>\n",
       "      <td>-0.205812</td>\n",
       "      <td>2.146448</td>\n",
       "      <td>5.627623</td>\n",
       "      <td>1.329111</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182402</td>\n",
       "      <td>-1.2071</td>\n",
       "      <td>1.2910</td>\n",
       "      <td>0.237785</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>-0.075352</td>\n",
       "      <td>1.286465</td>\n",
       "      <td>5.391815</td>\n",
       "      <td>1.312691</td>\n",
       "      <td>0.155544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.003031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.143902</td>\n",
       "      <td>-1.3802</td>\n",
       "      <td>1.5637</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.194728</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>2.808758</td>\n",
       "      <td>8.030176</td>\n",
       "      <td>1.353194</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.137908</td>\n",
       "      <td>-1.4787</td>\n",
       "      <td>1.4960</td>\n",
       "      <td>0.180747</td>\n",
       "      <td>0.187902</td>\n",
       "      <td>-0.053696</td>\n",
       "      <td>4.104418</td>\n",
       "      <td>7.961604</td>\n",
       "      <td>1.362513</td>\n",
       "      <td>0.025515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.131200</td>\n",
       "      <td>-1.2317</td>\n",
       "      <td>1.5648</td>\n",
       "      <td>0.178472</td>\n",
       "      <td>0.181081</td>\n",
       "      <td>0.075692</td>\n",
       "      <td>4.157256</td>\n",
       "      <td>8.641426</td>\n",
       "      <td>1.380187</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.131577</td>\n",
       "      <td>-1.3973</td>\n",
       "      <td>1.3526</td>\n",
       "      <td>0.178887</td>\n",
       "      <td>0.180757</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>3.914086</td>\n",
       "      <td>7.730254</td>\n",
       "      <td>1.373775</td>\n",
       "      <td>0.039722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0.127546</td>\n",
       "      <td>-1.7132</td>\n",
       "      <td>1.3323</td>\n",
       "      <td>0.176875</td>\n",
       "      <td>0.177953</td>\n",
       "      <td>-0.059980</td>\n",
       "      <td>5.260220</td>\n",
       "      <td>9.627271</td>\n",
       "      <td>1.395200</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean     Min     Max     StdDv       RMS  Skewness  Kurtosis  \\\n",
       "0     0.140067 -1.5920  1.3448  0.186773  0.192985 -0.186858  4.518489   \n",
       "1     0.187374 -1.4158  1.3472  0.202243  0.239738 -0.297777  3.182940   \n",
       "2     0.201925 -1.3502  1.1123  0.230012  0.259409 -0.205917  1.754806   \n",
       "3     0.177199 -1.3254  1.1532  0.223281  0.235517 -0.205812  2.146448   \n",
       "4     0.182402 -1.2071  1.2910  0.237785  0.239437 -0.075352  1.286465   \n",
       "...        ...     ...     ...       ...       ...       ...       ...   \n",
       "1795  0.143902 -1.3802  1.5637  0.194700  0.194728  0.025085  2.808758   \n",
       "1796  0.137908 -1.4787  1.4960  0.180747  0.187902 -0.053696  4.104418   \n",
       "1797  0.131200 -1.2317  1.5648  0.178472  0.181081  0.075692  4.157256   \n",
       "1798  0.131577 -1.3973  1.3526  0.178887  0.180757  0.011308  3.914086   \n",
       "1799  0.127546 -1.7132  1.3323  0.176875  0.177953 -0.059980  5.260220   \n",
       "\n",
       "      CrestFactor  ShapeFactor      FFT1  ...     FFT91     FFT92     FFT93  \\\n",
       "0        8.249357     1.377799  0.032111  ...  0.000141  0.000132  0.000123   \n",
       "1        5.905620     1.279463  0.035926  ...  0.001102  0.001102  0.001103   \n",
       "2        5.204907     1.284679  0.038505  ...  0.001468  0.001472  0.001475   \n",
       "3        5.627623     1.329111  0.063200  ...  0.000268  0.000253  0.000239   \n",
       "4        5.391815     1.312691  0.155544  ...  0.003041  0.003039  0.003037   \n",
       "...           ...          ...       ...  ...       ...       ...       ...   \n",
       "1795     8.030176     1.353194  0.029575  ...  0.000227  0.000229  0.000230   \n",
       "1796     7.961604     1.362513  0.025515  ...  0.000054  0.000049  0.000045   \n",
       "1797     8.641426     1.380187  0.021799  ...  0.000821  0.000821  0.000821   \n",
       "1798     7.730254     1.373775  0.039722  ...  0.001398  0.001396  0.001395   \n",
       "1799     9.627271     1.395200  0.020026  ...  0.000126  0.000126  0.000125   \n",
       "\n",
       "         FFT94     FFT95     FFT96     FFT97     FFT98     FFT99    FFT100  \n",
       "0     0.000114  0.000106  0.000099  0.000093  0.000087  0.000084  0.000082  \n",
       "1     0.001103  0.001103  0.001103  0.001104  0.001104  0.001103  0.001104  \n",
       "2     0.001477  0.001480  0.001482  0.001483  0.001485  0.001485  0.001486  \n",
       "3     0.000224  0.000211  0.000199  0.000189  0.000179  0.000174  0.000171  \n",
       "4     0.003035  0.003035  0.003033  0.003033  0.003033  0.003032  0.003031  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1795  0.000231  0.000231  0.000232  0.000233  0.000233  0.000233  0.000234  \n",
       "1796  0.000040  0.000035  0.000031  0.000027  0.000024  0.000021  0.000020  \n",
       "1797  0.000821  0.000821  0.000821  0.000821  0.000821  0.000821  0.000821  \n",
       "1798  0.001393  0.001391  0.001390  0.001389  0.001388  0.001388  0.001388  \n",
       "1799  0.000124  0.000123  0.000122  0.000121  0.000121  0.000121  0.000121  \n",
       "\n",
       "[1800 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalization_status='RobustScaler'   \n",
    "''' Choices:\n",
    "                                        1. Normalization\n",
    "                                        2. StandardScaler\n",
    "                                        3. MinMaxScaler\n",
    "                                        4. RobustScaler\n",
    "                                        5. Normalizer\n",
    "                                        6. WithoutNormalization   '''\n",
    "input_data_columns=data_columns_PrimaryStatFeatures+data_columns_FFT_Features\n",
    "\n",
    "if (normalization_status=='Normalization'):\n",
    "    data_array=preprocessing.normalize(input_data,norm='l2',axis=0)\n",
    "    input_data=pd.DataFrame(data_array,columns=input_data_columns)\n",
    "elif (normalization_status=='StandardScaler'):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaled_df = scaler.fit_transform(input_data)\n",
    "    input_data = pd.DataFrame(scaled_df, columns=input_data_columns)\n",
    "elif (normalization_status=='MinMaxScaler'):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(input_data)\n",
    "    input_data = pd.DataFrame(scaled_df, columns=input_data_columns)\n",
    "elif (normalization_status=='RobustScaler'):\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    scaled_df = scaler.fit_transform(input_data)\n",
    "    input_data = pd.DataFrame(scaled_df, columns=input_data_columns)\n",
    "elif (normalization_status=='Normalizer'):\n",
    "    scaler = preprocessing.Normalizer()\n",
    "    scaled_df = scaler.fit_transform(input_data)\n",
    "    input_data = pd.DataFrame(scaled_df, columns=input_data_columns)\n",
    "elif (normalization_status=='WithoutNormalization'):\n",
    "    print ('No normalization is required')\n",
    "\n",
    "target_data=pd.DataFrame(data['Fault'],columns=['Fault'],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
